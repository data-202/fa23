{
  "hash": "a4c8199d509156757a334cf128a46d0b",
  "result": {
    "markdown": "---\ntitle: \"DATA 202 - Week 7\"\nsubtitle: \"Bivariate analysis\"\nauthor: \"Nathan Alexander, PhD\"\ninstitute: \"Center for Applied Data Science and Analytics\"\nformat: \n  html: default\n  revealjs:\n    output-file: week7-slides.html\n    height: 900\n    width: 1600\n    smaller: false\n    scrollable: true\n    slide-number: c/t #< collapsted/total\n    logo: \"img/howard-logo.jpg\"\n    footer: \"[Course Data GitHub](https://github.com/data-202)\"\n    toc: false\n    theme: simple\n    echo: true\n    incremental: false\n---\n\n\n## Part I: Context\n\n------------------------------------------------------------------------\n\nRacial injustice is a leading historical and contemporary social issue across the globe.\n\n![Image from Prison Policy Initiative](img/wk7-a-2.png)\n\n------------------------------------------------------------------------\n\nBuilding new theories around the various types of injustices requires empirical analysis.\n\n-   One method is to read recent articles in peer-reviewed journals.\n\n-   Another method is to explore the various ways one may view injustice.\n\n-   For research, you may seek to test the validity of certain claims.\n\n## ![Image from BestColleges.com](img/wk7-a-3.jpg)\n\n### Understanding the social in justice\n\nHow should we define social justice?\n\n-   Identify two to three definitions of social justice to share.\n\n    -   Locate a few open source articles or periodicals.\n\n-   What are the *similarities* between the different definitions?\n\n-   What are the *differences* between the different definitions?\n\n![Image from Northeast Global News](img/wk7-a-1.jpg)\n\n------------------------------------------------------------------------\n\n#### The Murder of George Floyd\n\nWhat do we know about George Floyd and the events that occured on May 25, 2020?\n\n![Image from Mass Humanities](img/wk7-a-4.jpg)\n\nIn your free time you can read [How George Floyd Was Killed in Police Custody. Image from NY Times.](https://www.nytimes.com/2020/05/31/us/george-floyd-investigation.html) to understand a step-by-step reconstruction of the incident.\n\n------------------------------------------------------------------------\n\n##### Yahoo! News Race and Justice poll results\n\nPoll results are stored in the `yahoo_data` data set located in the `critstats` package.\n\n------------------------------------------------------------------------\n\n## Part II: Content\n\nThis week's topics focus on bivariate analysis.\n\nThe goal of a bivariate analysis is to understand the relationship between two variables.\n\nThere are a few common ways to perform bivariate analysis:\n\n-   Estimating differences in proportions\n\n-   Scatterplots\n\n-   Correlation coefficients\n\n-   Simple linear regression\n\n------------------------------------------------------------------------\n\n### Simple linear regression\n\nA simple linear regression (sometimes referenced as a bivariate regression) is a linear equation describing the relationship between an **explanatory** variable and an **outcome** variable.\n\nThere is an assumption that the explanatory variable influences the outcome variable, and not the other way around.\n\nTake, for example, a variable $y_i$ which denotes the *income* of some individual in a sample, and we index this data using $i$ where $i \\in \\{1, 2, ..., n\\}$. We can let some other variable in our data $x_i$ represent the *years of education* for the same individual. A simple linear regression equation of these variables take the following form: $$y_i = b_0 + b_{1}x_{i} + e_i$$\n\nwhere $b_i$ is the sample estimate of the slope of the regression line with respect to the years of education and $b_0$ is the sample estimate for the vertical intercept of the regression line.\n\n------------------------------------------------------------------------\n\n### Correlation coefficients and scatterplots\n\nAs a reminder, correlation ranges from -1 to 1. It gives us an indication on two things:\n\n-   The direction of the relationship between the two variables\n\n-   The strength of the relationship between the two variables\n\nOutliers matter a lot when considering correlation coefficients.\n\n## ![Outliers in Pearson correlation. Image from Stats and R. Image from Datatab.net](img/wk7-b-1.png)\n\n### Estimating differences in proportions\n\nWhen generating cross tabulations, we can make sense of a few bivariate tests:\n\n-   Differences in proportions\n\n-   Standard errors of the difference in proportions\n\n-   Confidence intervals for the differences\n\n-   T-test for differences in proportions\n\n## ![Image from DataTab.net](img/wk7-b-2.png){width=\"50%\"}\n\n## Part III: Code\n\nThe code for this week will prepare you to run analyses for [Paper #2](papers/paper2.qmd).\n\n[Paper #2](papers/paper2.qmd) is a short exploration of a data set in the `forcats` package.\n\nA sample **RScript** and workflow is provided here.\n\n------------------------------------------------------------------------\n\n### Write preamble\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ---\n# title: Exploring associations between income and political party in the US\n# subtitle: sample paper 2\n# author: Nathan Alexander\n# course: DATA 202 - fall 2023\n# ---\n\n# research inquiry: does income relate to political party support in the US?\n# data: 2020 sample data from the General Social Survey (GSS)\n# note(s): variables should be mutated and recoded into two levels\n```\n:::\n\n\n------------------------------------------------------------------------\n\n### step 0: install packages and load libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"tidyverse\", repos = \"http://cran.us.r-project.org\")\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(tidyr)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n### step 1: view `gss_cat` data in the package `forcats`\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngetwd() # check working directory\n?gss_cat # view data documentation\ngss_cat # call data frame\nglimpse(gss_cat) # glimpse data\nsummary(gss_cat) # view summary of data\n```\n:::\n\n\n------------------------------------------------------------------------\n\n### step 2: clean and manage data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngss_cat_clean <- gss_cat %>% \n  na.omit() %>% \n  select(year, rincome, partyid) %>% \n  rename(income = rincome) %>% \n  rename(party = partyid)\n\ngss_cat_clean # view cleaned data\n```\n:::\n\n\n------------------------------------------------------------------------\n\n### step 3: subset data: year == 2000\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- gss_cat_clean %>% \n  filter(year==2000)\n\nhead(df) # view top of data\ntail(df) # view bottom of data\nsummary(df) # check data\n```\n:::\n\n\n------------------------------------------------------------------------\n\n### step 4: inspect and transform income variable into two levels\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## create a frequency table of each level in the income variable\ndf %>% count(party)\n\n## drop 'No answer', 'Don't know', 'Refused', and 'Not applicable' levels\ndf <- df %>%  \n  filter(income != \"No answer\",\n         income != \"Don't know\",\n         income != \"Refused\",\n         income != \"Not applicable\") %>% \n  droplevels() # use droplevels() to remove levels from variable for factors\n\n## use levels() function to view levels for income variable\nlevels(df$income)\n\n## create two levels: below $20,000 and above $20,000\ndf <- df %>% \n  mutate(income = fct_recode(income, \n                             \"More than 20000\" = \"$25000 or more\",\n                             \"More than 20000\" = \"$20000 - 24999\",\n                             \"Less than 20000\" = \"$15000 - 19999\",\n                             \"Less than 20000\" = \"$10000 - 14999\",\n                             \"Less than 20000\" = \"$8000 to 9999\",\n                             \"Less than 20000\" = \"$7000 to 7999\",\n                             \"Less than 20000\" = \"$6000 to 6999\",\n                             \"Less than 20000\" = \"$5000 to 5999\",\n                             \"Less than 20000\" = \"$4000 to 4999\",\n                             \"Less than 20000\" = \"$3000 to 3999\",\n                             \"Less than 20000\" = \"$1000 to 2999\",\n                             \"Less than 20000\" = \"Lt $1000\"))\n\n## view a summary of your transformed data frame\nsummary(df)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n### step 5: inspect and transform party variable into two levels\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## create a frequency table of each level in the party variable\ndf %>% count(party)\n\n## drop 'No answer', 'Independent' and 'Other Party' levels\ndf <- df %>%  \n  filter(party != \"No answer\",\n         party != \"Independent\",\n         party != \"Other party\") %>% \n  droplevels() # use droplevels() to remove levels from variable for factors\n\n## create two levels: 'Republican' and 'Democrat'\ndf <- df %>% \n  mutate(party = fct_recode(party,\n                            \"Republican\" = \"Strong republican\",\n                            \"Republican\" = \"Not str republican\",\n                            \"Republican\" = \"Ind,near rep\",\n                            \"Democrat\" = \"Ind,near dem\",\n                            \"Democrat\" = \"Not str democrat\",\n                            \"Democrat\" = \"Strong democrat\"))\n\n## remove year from data frame\ndf <- df %>% \n  select(-year)\n\n## view a summary of the data to check for any errors\nsummary(df)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n### step 6: visualize data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## create a frequency table and bar graph of income \ntable.income = table(df$income)\ntable.income\nbarplot(table.income,\n        main = \"Bar graph of Income\",\n        xlab = \"Respondent Income\",\n        ylab = \"Frequency\")\n```\n\n```{.r .cell-code}\n## the below code produces the same output as above with specifications\nbarplot(table(df$income),\n        main = \"Bar graph of Income\",\n        col = \"lightgreen\",\n        xlab = \"Respondent Income\",\n        ylab = \"Frequency\",\n        ylim = c(0,650)) # this y-axis range: (0, 650) works best for my plot\n```\n\n```{.r .cell-code}\n## create a frequency table and bar graph of party \ntable.party = table(df$party)\ntable.party\nbarplot(table.party,\n        main = \"Bar graph of Party\",\n        xlab = \"Respondent Party\",\n        ylab = \"Frequency\")\n```\n\n```{.r .cell-code}\n## the below code produces the same output as above with specifications\nbarplot(table(df$party),\n        main = \"Bar graph of Party\",\n        col = c(\"red\",\"blue\"),\n        xlab = \"Respondent Party\",\n        ylab = \"Frequency\",\n        ylim = c(0,600)) # this y-axis range: (0, 550) works best for my plot\n```\n\n```{.r .cell-code}\n## create a stacked bar plot of the proportions\n#### question: which of the two plots do you prefer, why?\nplot(df$income, df$party)\n```\n\n```{.r .cell-code}\nplot(df$party, df$income)\n```\n\n```{.r .cell-code}\n## the below code produces similar outputs as above with specifications\nplot(df$party, df$income,\n     main = \"Mosaic Plot of Political Party and Income\",\n     col = c(\"lightyellow\",\"lightgreen\"),\n     xlab = \"Political Party\",\n     ylab = \"Income\")\n```\n:::\n\n\n------------------------------------------------------------------------\n\n### step 7: create a basic cross tab for manual calculations\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## gather sample size\nn = count(df)\nn\n\n## view a basic cross tabulation\ntable(df$income, df$party)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n### step 8: statistical analyses in R\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## load required libraries (and packages, where needed)\ninstall.packages(\"descr\", repos = \"http://cran.us.r-project.org\")\nlibrary(descr)\n\ninstall.packages(\"Hmisc\", repos = \"http://cran.us.r-project.org\")\nlibrary(Hmisc)\n\n## create a cross tab (list dependent variable in your hypothesis first)\ncrosstab(df$party, df$income)\n\n## add column percentages to the cross tab\ncrosstab(df$party, df$income,\n         prop.c=T) # add column percentages\n```\n\n```{.r .cell-code}\n## add row percentages to the cross tab\ncrosstab(df$party, df$income,\n         prop.r=T) # add row percentages\n\n## get expected frequencies and cell chi-square contributions\ncrosstab(df$party, df$income,\n         expected = T, # get expected values\n         prop.chisq=T) # get chi-square contribution\n\n## get critical value of chi-square, p=.05, df=1\n#### recall: df = (r-1)(c-1)\nqchisq(.05, 1, lower.tail=F)\n\n## get chi-square statistic\nchisq.test(df$party, df$income)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n### step 9: describe some initial limitations of analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### limitation 1: sampling error\n# data come from a sample and there are likely differences in other samples\n\n### limitation 2: category reductions\n# creating two levels for the variables greatly impacted the diversity of responses\n\n### limitation 3: cases dropped\n# sample was further impacted by the number of values dropped in the analysis\n\n### limitation 4: chi-square test\n# the chi-square test does not tell us about the strength or direction of association\n```\n:::\n\n\n------------------------------------------------------------------------\n\n### **Next up**: Week 8\n",
    "supporting": [
      "week7_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}